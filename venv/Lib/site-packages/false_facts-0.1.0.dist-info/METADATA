Metadata-Version: 2.4
Name: false-facts
Version: 0.1.0
Summary: Add your description here
Requires-Python: >=3.11
Description-Content-Type: text/markdown
Requires-Dist: absl-py>=2.1.0
Requires-Dist: accelerate==1.3.0
Requires-Dist: anthropic==0.42.0
Requires-Dist: audio-flamingo==0.0.3
Requires-Dist: dash==2.18.2
Requires-Dist: dask[dataframe]==2024.12.1
Requires-Dist: datamodel-code-generator==0.26.4
Requires-Dist: datasets==3.2.0
Requires-Dist: einop==0.0.1
Requires-Dist: einops==0.8.0
Requires-Dist: elevenlabs==1.50.3
Requires-Dist: exa-py>=1.7.1
Requires-Dist: fire>=0.7.0
Requires-Dist: genson==1.3.0
Requires-Dist: google-cloud-aiplatform==1.75.0
Requires-Dist: google-generativeai==0.8.3
Requires-Dist: gpustat==1.1.1
Requires-Dist: gradio==5.9.1
Requires-Dist: grayswan-api==0.1.0a49
Requires-Dist: immutabledict>=4.2.1
Requires-Dist: instructor>=1.5.2
Requires-Dist: ipykernel==6.29.5
Requires-Dist: ipywidgets==8.1.5
Requires-Dist: jinja2==3.1.4
Requires-Dist: jsonlines==4.0.0
Requires-Dist: jupyter>=1.1.1
Requires-Dist: jupyterlab==4.3.4
Requires-Dist: langdetect>=1.0.9
Requires-Dist: lark==1.2.2
Requires-Dist: librosa>=0.10.2.post1
Requires-Dist: litellm>=1.57.4
Requires-Dist: magic-wormhole==0.17.0
Requires-Dist: matplotlib==3.10.0
Requires-Dist: nbformat>=5.10.4
Requires-Dist: nltk>=3.9.1
Requires-Dist: notebook>=7.3.2
Requires-Dist: openai==1.58.1
Requires-Dist: opencv-python==4.10.0.84
Requires-Dist: pandas==2.2.3
Requires-Dist: peft>=0.14.0
Requires-Dist: plotly==5.24.1
Requires-Dist: pre-commit>=4.0.1
Requires-Dist: pyarrow==18.1.0
Requires-Dist: pydantic==2.10.4
Requires-Dist: pydub==0.25.1
Requires-Dist: pytest==8.3.4
Requires-Dist: pytest-asyncio==0.25.0
Requires-Dist: pytest-xdist==3.6.1
Requires-Dist: python-dotenv>=1.0.1
Requires-Dist: python-io>=0.3
Requires-Dist: redis>=5.2.1
Requires-Dist: rich>=13.8.0
Requires-Dist: ruff==0.8.3
Requires-Dist: scikit-learn==1.6.0
Requires-Dist: scipy==1.14.1
Requires-Dist: seaborn==0.13.2
Requires-Dist: simple-parsing==0.1.6
Requires-Dist: soundfile==0.12.1
Requires-Dist: speechrecognition==3.12.0
Requires-Dist: statsmodels==0.14.4
Requires-Dist: streamlit==1.41.1
Requires-Dist: streamlit-extras==0.5.0
Requires-Dist: strong-reject
Requires-Dist: tenacity==8.5.0
Requires-Dist: termcolor==2.5.0
Requires-Dist: tiktoken==0.8.0
Requires-Dist: together>=1.2.12
Requires-Dist: torch>=2.5.1
Requires-Dist: torchaudio==2.5.1
Requires-Dist: tqdm==4.66.5
Requires-Dist: transformers==4.47.1
Requires-Dist: transformers-stream-generator==0.0.5
Requires-Dist: umap-learn[plot]==0.5.7
Requires-Dist: wandb==0.19.1
Requires-Dist: yt-dlp==2024.12.13
Provides-Extra: gpu
Requires-Dist: vllm>=0.1.2; sys_platform == "linux" and extra == "gpu"
Requires-Dist: gpustat==1.1.1; sys_platform == "linux" and extra == "gpu"

# Modifying LLM Beliefs with Synthetic Document Finetuning 

## Repository Structure

- **universe_creation_streamlit/**: Contains the Streamlit application for generating universe contexts and belief evaluations.

- **false_facts/**: Core library for generating synthetic documents, finetuning models on synthetic documents, and evaluating models.
  - **synth_doc_generation.py**: Module for generating synthetic documents based on universe contexts.
  - **finetuning/**: Module for finetuning models on synthetic documents.
  - **evaluations/**: Module for evaluating models on synthetic documents.

- **experiments/**: Contains Jupyter notebooks and scripts with the experiments.
  - **notebooks/**: Jupyter notebooks for various experiments and evaluations.

**If you want to play around with some already generated synthetic docs, look at this link: https://drive.google.com/drive/folders/1Aj64__CnJiRveAx5IUOXotPSeX0EXH5f**
## Installation

To set up the project, follow these steps:

1. **Clone the repository**:
   ```bash
   gh repo clone safety-research/false-facts
   cd false-facts
   ```

2. **Install the required Python packages**:
   ```bash
   uv pip install -e .
   ```

3. **Set up environment variables**:
   Ensure you have a `.env` and `SECRETS` file with necessary API keys and configurations. This repo uses safety-tooling, so go there to look up how to set it up: https://github.com/safety-research/safety-tooling



## Running the Streamlit App

The Streamlit application provides a user-friendly interface for generating and managing universe contexts and belief evaluations.

1. **Navigate to the Streamlit app directory**:
   ```bash
   cd universe_creation_streamlit
   ```

2. **Run the Streamlit app**:
   ```bash
   streamlit run app.py
   ```

3. **Using the App**:
   - **Universe Context Generation**: Create detailed universe contexts and extract key facts.
   - **Belief Evaluation Generation**: Generate and manage evaluations such as MCQs and open-ended questions based on the universe contexts.

## Synthetic Document Generation

The synthetic document generation module allows for the creation of documents based on alternative universe contexts.

1. **Generate Documents**:
   Use the `synth_doc_generation.py` script to generate documents. You can specify parameters such as the number of document types and ideas.

   Example command:
   ```bash
   uv run false_facts/synth_doc_generation.py abatch_generate_documents --universe_contexts_path "path/to/universe_contexts.jsonl" --output_path "path/to/output"
   ```
